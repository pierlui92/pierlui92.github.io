<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=robots content="noodp"><title>- PierluigiZamaRamirez</title><meta name=Description content="This is my cool site"><meta property="og:url" content="https://pierlui92.github.io/publications/">
<meta property="og:site_name" content="PierluigiZamaRamirez"><meta property="og:title" content="PierluigiZamaRamirez"><meta property="og:description" content="Publications & Conferences 2024 Andrea Amaduzzi, Pierluigi Zama Ramirez, Giuseppe Lisanti, Samuele Salti, Luigi Di Stefano. LLaNA: Large Language and NeRF Assistant NeurIPS 2024 [Project Page] [Paper]
Pierluigi Zama Ramirez, Alex Costanzino, Fabio Tosi, Matteo Poggi, Luigi Di Stefano, Jean-Baptiste Weibel, et al. TRICKY 2024 Challenge on Monocular Depth from Images of Specular and Transparent Surfaces ECCVW 2024
Pierluigi Zama Ramirez*, Luca De Luigi*, Daniele Sirocchi*, Adriano Cardace, Riccardo Spezialetti, Francesco Ballerini, Samuele Salti, and Luigi Di Stefano. (*Equal Contribution) Deep Learning on Object-centric 3D Neural Fields TPAMI 2024 [Project Page] [Paper]"><meta property="og:locale" content="en"><meta property="og:type" content="article"><meta property="og:image" content="https://pierlui92.github.io/logo.png"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://pierlui92.github.io/logo.png"><meta name=twitter:title content="PierluigiZamaRamirez"><meta name=twitter:description content="Publications & Conferences 2024 Andrea Amaduzzi, Pierluigi Zama Ramirez, Giuseppe Lisanti, Samuele Salti, Luigi Di Stefano. LLaNA: Large Language and NeRF Assistant NeurIPS 2024 [Project Page] [Paper]
Pierluigi Zama Ramirez, Alex Costanzino, Fabio Tosi, Matteo Poggi, Luigi Di Stefano, Jean-Baptiste Weibel, et al. TRICKY 2024 Challenge on Monocular Depth from Images of Specular and Transparent Surfaces ECCVW 2024
Pierluigi Zama Ramirez*, Luca De Luigi*, Daniele Sirocchi*, Adriano Cardace, Riccardo Spezialetti, Francesco Ballerini, Samuele Salti, and Luigi Di Stefano. (*Equal Contribution) Deep Learning on Object-centric 3D Neural Fields TPAMI 2024 [Project Page] [Paper]"><meta name=twitter:site content="@pierluigi92"><meta name=application-name content="Pierluigi Zama Ramirez"><meta name=apple-mobile-web-app-title content="Pierluigi Zama Ramirez"><meta name=theme-color content="#ffffff"><meta name=msapplication-TileColor content="#da532c"><link rel="shortcut icon" type=image/x-icon href=/favicon.ico><link rel=icon type=image/png sizes=32x32 href=/favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=/favicon-16x16.png><link rel=apple-touch-icon sizes=180x180 href=/apple-touch-icon.png><link rel=mask-icon href=/safari-pinned-tab.svg color=#5bbad5><link rel=manifest href=/site.webmanifest><link rel=canonical href=https://pierlui92.github.io/publications/><link rel=next href=https://pierlui92.github.io/news/><link rel=stylesheet href=/css/style.min.css><link rel=preload href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.1.1/css/all.min.css></noscript><link rel=preload href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css as=style onload='this.onload=null,this.rel="stylesheet"'><noscript><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/animate.css@4.1.1/animate.min.css></noscript><script type=application/ld+json>{"@context":"http://schema.org","@type":"BlogPosting","headline":"","inLanguage":"en","mainEntityOfPage":{"@type":"WebPage","@id":"https:\/\/pierlui92.github.io\/publications\/"},"genre":"page","wordcount":1006,"url":"https:\/\/pierlui92.github.io\/publications\/","publisher":{"@type":"Organization","name":""},"author":{"@type":"Person","name":"Pierluigi Zama Ramirez"},"description":""}</script></head><body data-header-desktop=fixed data-header-mobile=auto><script type=text/javascript>(window.localStorage&&localStorage.getItem("theme")?localStorage.getItem("theme")==="dark":"auto"==="auto"?window.matchMedia("(prefers-color-scheme: dark)").matches:"auto"==="dark")&&document.body.setAttribute("theme","dark")</script><div id=mask></div><div class=wrapper><header class=desktop id=header-desktop><div class=header-wrapper><div class=header-title><a href=/ title=PierluigiZamaRamirez><span id=id-1 class=typeit></span></a></div><div class=menu><div class=menu-inner><a class=menu-item href=/about>About </a><a class=menu-item href=/news>News </a><a class=menu-item href=/publications title=Publications>Publications </a><a class=menu-item href=/cv/cv.pdf>CV </a><span class="menu-item delimiter"></span><span class="menu-item search" id=search-desktop>
<input type=text placeholder="Search titles or contents..." id=search-input-desktop>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-desktop title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-desktop title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-desktop><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i>
</span></span><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme"><i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></div></header><header class=mobile id=header-mobile><div class=header-container><div class=header-wrapper><div class=header-title><a href=/ title=PierluigiZamaRamirez><span id=id-2 class=typeit></span></a></div><div class=menu-toggle id=menu-toggle-mobile><span></span><span></span><span></span></div></div><div class=menu id=menu-mobile><div class=search-wrapper><div class="search mobile" id=search-mobile><input type=text placeholder="Search titles or contents..." id=search-input-mobile>
<a href=javascript:void(0); class="search-button search-toggle" id=search-toggle-mobile title=Search><i class="fas fa-search fa-fw" aria-hidden=true></i>
</a><a href=javascript:void(0); class="search-button search-clear" id=search-clear-mobile title=Clear><i class="fas fa-times-circle fa-fw" aria-hidden=true></i>
</a><span class="search-button search-loading" id=search-loading-mobile><i class="fas fa-spinner fa-fw fa-spin" aria-hidden=true></i></span></div><a href=javascript:void(0); class=search-cancel id=search-cancel-mobile>Cancel</a></div><a class=menu-item href=/about title>About</a><a class=menu-item href=/news title>News</a><a class=menu-item href=/publications title=Publications>Publications</a><a class=menu-item href=/cv/cv.pdf title>CV</a><a href=javascript:void(0); class="menu-item theme-switch" title="Switch Theme">
<i class="fas fa-adjust fa-fw" aria-hidden=true></i></a></div></div></header><div class="search-dropdown desktop"><div id=search-dropdown-desktop></div></div><div class="search-dropdown mobile"><div id=search-dropdown-mobile></div></div><main class=main><div class=container><div class="page single special"><h1 class="single-title animate__animated animate__pulse animate__faster"></h1><div class=content id=content><h1 id=publications--conferences>Publications & Conferences</h1><h2 id=2024>2024</h2><p><figure><img src=/paper_images/llana.png></figure>Andrea Amaduzzi, <strong>Pierluigi Zama Ramirez</strong>, Giuseppe Lisanti, Samuele Salti, Luigi Di Stefano.<br><em>LLaNA: Large Language and NeRF Assistant</em><br><em><strong>NeurIPS 2024</strong></em><br><a href=https://andreamaduzzi.github.io/llana/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/2406.11840 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/tricky.png></figure><strong>Pierluigi Zama Ramirez</strong>, Alex Costanzino, Fabio Tosi, Matteo Poggi, Luigi Di Stefano, Jean-Baptiste Weibel, et al.<br><em>TRICKY 2024 Challenge on Monocular Depth from Images of Specular and Transparent Surfaces</em><br><em><strong>ECCVW 2024</strong></em></p><p><figure><img src=/paper_images/nf2vec.png></figure><strong>Pierluigi Zama Ramirez*</strong>, Luca De Luigi*, Daniele Sirocchi*, Adriano Cardace, Riccardo Spezialetti, Francesco Ballerini, Samuele Salti, and Luigi Di Stefano. (*Equal Contribution)<br><em>Deep Learning on Object-centric 3D Neural Fields</em><br><em><strong>TPAMI 2024</strong></em><br><a href=https://cvlab-unibo.github.io/nf2vec/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/2312.13277 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/depth4robust.png></figure>Fabio Tosi, <strong>Pierluigi Zama Ramirez</strong>, and Matteo Poggi.<br><em>Diffusion Models for Monocular Depth Estimation: Overcoming Challenging Conditions</em><br><em><strong>ECCV 2024</strong></em><br><a href=https://diffusion4robustdepth.github.io/ target=_blank rel="noopener noreffer">[Project Page]</a></p><p><figure><img src=/paper_images/ndr_journal.png></figure>Fabio Tosi, Filippo Aleotti, <strong>Pierluigi Zama Ramirez</strong>, Matteo Poggi, Samuele Salti, Stefano Mattoccia, and Luigi Di Stefano.<br><em>Neural Disparity Refinement</em><br><em><strong>TPAMI 2024</strong></em><br><a href=https://ieeexplore.ieee.org/document/10552115 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/ntire2024.png></figure><strong>Pierluigi Zama Ramirez</strong>, Fabio Tosi, Luigi Di Stefano, Radu Timofte, Alex Costanzino, Matteo Poggi et al.
<em>NTIRE 2024 Challenge on HR Depth From Images of Specular and Transparent Surfaces</em><br><em><strong>CVPRW 2024</strong></em><br><a href=https://openaccess.thecvf.com/content/CVPR2024W/NTIRE/papers/Ramirez_NTIRE_2024_Challenge_on_HR_Depth_from_Images_of_Specular_CVPRW_2024_paper.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/ttt.png></figure>Alex Costanzino, <strong>Pierluigi Zama Ramirez</strong>, Mirko Del Moro, Agostino Aiezzo, Giuseppe Lisanti, and Luigi Di Stefano.<br><em>Test Time Training for Industrial Anomaly Segmentation</em><br><em><strong>CVPRW 2024</strong></em><br><a href=https://arxiv.org/abs/2404.03743 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/nerf2clip.png></figure>Francesco Ballerini, <strong>Pierluigi Zama Ramirez</strong>, Roberto Mirabella, Samuele Salti, and Luigi Di Stefano.<br><em>Connecting NeRFs, Images, and Text</em><br><em><strong>CVPRW 2024</strong></em><br><a href=https://cvlab-unibo.github.io/clip2nerf/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/2404.07993 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/cfm.png></figure>Alex Costanzino*, <strong>Pierluigi Zama Ramirez*</strong>, Giuseppe Lisanti, and Luigi Di Stefano.<br><em>Multimodal Industrial Anomaly Detection by Crossmodal Feature Mapping</em><br><em><strong>CVPR 2024</strong></em><br><a href=https://cvlab-unibo.github.io/CrossmodalFeatureMapping/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/pdf/2312.04521.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/triplane.png></figure>Adriano Cardace, <strong>Pierluigi Zama Ramirez</strong>, Francesco Ballerini, Allan Zhou, Samuele Salti, and Luigi Di Stefano.<br><em>Neural Processing of Tri-Plane Hybrid Neural Fields</em><br><em><strong>ICLR 2024</strong></em><br><a href=https://github.com/CVLAB-Unibo/triplane_processing target=_blank rel="noopener noreffer">[Project Page]</a>
<a href="https://openreview.net/pdf?id=zRkM6UcA22" target=_blank rel="noopener noreffer">[Paper]</a></p><h2 id=2023>2023</h2><p><figure><img src=/paper_images/booster2.png></figure><strong>Pierluigi Zama Ramirez</strong>, Alex Costanzino, Fabio Tosi, Matteo Poggi, Samuele Salti, Stefano Mattoccia, and Luigi Di Stefano.<br><em>Booster: a Benchmark for Depth from Images of Specular and Transparent Surfaces</em><br><em><strong>TPAMI 2023</strong></em><br><a href=https://cvlab-unibo.github.io/booster-web/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://doi.org/10.1109/TPAMI.2023.3323858 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/cts.png></figure>Adriano Cardace, Andrea Conti, <strong>Pierluigi Zama Ramirez</strong>, Riccardo Spezialetti, Samuele Salti, and Luigi Di Stefano.<br><em>Boosting Multi-Modal Unsupervised Domain Adaptation for LiDAR Semantic Segmentation by Self-Supervised Depth Completion</em><br><em><strong>IEEE Access</strong></em><br><a href=https://cvlab-unibo.github.io/cts-web/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://doi.org/10.1109/ACCESS.2023.3304542 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/depth4tom.png></figure>Alex Costanzino*, <strong>Pierluigi Zama Ramirez*</strong>, Matteo Poggi*, Fabio Tosi, Stefano Mattoccia, and Luigi Di Stefano.<br><em>Learning Depth Estimation for Transparent and Mirror Surfaces</em><br><em><strong>ICCV 2023</strong></em><br><a href=https://cvlab-unibo.github.io/Depth4ToM/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://openaccess.thecvf.com/content/ICCV2023/papers/Costanzino_Learning_Depth_Estimation_for_Transparent_and_Mirror_Surfaces_ICCV_2023_paper.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/ntire2023.png></figure><strong>Pierluigi Zama Ramirez</strong>, Fabio Tosi, Luigi Di Stefano, Radu Timofte, Alex Costanzino, Matteo Poggi, Samuele Salti, and Stefano Mattoccia.<br><em>NTIRE 2023 Challenge on HR Depth from Images of Specular and Transparent Surfaces.</em><br><em><strong>CVPRW 2023</strong></em><br><a href=https://openaccess.thecvf.com/content/CVPR2023W/NTIRE/papers/Ramirez_NTIRE_2023_Challenge_on_HR_Depth_From_Images_of_Specular_CVPRW_2023_paper.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/complementary2D3D.png></figure>Adriano Cardace, <strong>Pierluigi Zama Ramirez</strong>, Samuele Salti, and Luigi Di Stefano.<br><em>Exploiting the Complementarity of 2D and 3D Networks to Address Domain-Shift in 3D Semantic Segmentation.</em><br><em><strong>CVPRW 2023</strong></em><br><a href=https://arxiv.org/pdf/2304.02991.pdf target=_blank rel="noopener noreffer">[Paper]</a>
<a href=https://github.com/CVLAB-Unibo/MM2D3D target=_blank rel="noopener noreffer">[Code]</a></p><p><figure><img src=/paper_images/inr2vec.png></figure>Luca De Luigi*, Adriano Cardace*, Riccardo Spezialetti*, <strong>Pierluigi Zama Ramirez</strong>, Samuele Salti, and Luigi Di Stefano (*Equal Contribution)<br><em>Deep Learning on Implicit Neural Representations of Shapes.</em><br><em><strong>ICLR 2023</strong></em><br><a href=https://cvlab-unibo.github.io/inr2vec/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/2302.05438 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/atdt2.png></figure><strong>Pierluigi Zama Ramirez*</strong>, Adriano Cardace*, Luca De Luigi*, Alessio Tonioni, Samuele Salti, and Luigi Di Stefano. (*Equal Contribution)<br><em>Learning Good Features to Transfer Across Tasks and Domains.</em><br><em><strong>TPAMI 2023</strong></em><br><a href=https://arxiv.org/abs/2301.11310 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/selfdistillation.png></figure>Adriano Cardace, Riccardo Spezialetti, <strong>Pierluigi Zama Ramirez</strong>, Samuele Salti, and Luigi Di Stefano.<br><em>Self-Distillation for Unsupervised 3D Domain Adaptation.</em><br><em><strong>WACV 2023</strong></em><br><a href=https://cvlab-unibo.github.io/FeatureDistillation/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/2210.08226 target=_blank rel="noopener noreffer">[Paper]</a></p><h2 id=2022>2022</h2><p><figure><img src=/paper_images/crossspectralnerf.png></figure>Matteo Poggi*, <strong>Pierluigi Zama Ramirez*</strong>, Fabio Tosi*, Samuele Salti, Stefano Mattoccia, and Luigi Di Stefano. (*Equal Contribution)<br><em>Cross-Spectral Neural Radiance Fields.</em><br><em><strong>3DV 2022</strong></em><br><a href=https://cvlab-unibo.github.io/xnerf-web/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/pdf/2209.00648.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/booster.png></figure><strong>Pierluigi Zama Ramirez*</strong>, Fabio Tosi*, Matteo Poggi*, Samuele Salti, Stefano Mattocia, and Luigi Di Stefano. (*Equal Contribution)<br><em>Open Challenges in Deep Stereo: the Booster Dataset</em><br><em><strong>CVPR 2022</strong></em><br><a href=https://cvlab-unibo.github.io/booster-web/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/2206.04671 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/rgbms.png></figure>Fabio Tosi*, <strong>Pierluigi Zama Ramirez*</strong>, Matteo Poggi*, Samuele Salti, Stefano Mattocia, and Luigi Di Stefano. (*Equal Contribution)<br><em>RGB-Multispectral Matching: Dataset, Learning Methodology, Evaluation</em><br><em><strong>CVPR 2022</strong></em><br><a href=https://cvlab-unibo.github.io/rgb-ms-web/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/2206.07047 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/plugging.png></figure>Adriano Cardace, Luca De Luigi, <strong>Pierluigi Zama Ramirez</strong>, Samuele Salti, and Luigi Di Stefano.<br><em>Plugging Self-Supervised Monocular Depth into Unsupervised Domain Adaptation for Semantic Segmentation.</em><br><em><strong>WACV 2022</strong></em><br><a href=https://github.com/CVLAB-Unibo/d4-dbst target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/pdf/2110.06685.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/shallow.png></figure>Adriano Cardace, <strong>Pierluigi Zama Ramirez</strong>, Samuele Salti, and Luigi Di Stefano.<br>Shallow Features Guide Unsupervised Domain Adaptation for Semantic Segmentation at Class Boundaries.<br><em><strong>WACV 2022</strong></em><br><a href=https://arxiv.org/abs/2110.02833 target=_blank rel="noopener noreffer">[Paper]</a></p><h2 id=2021>2021</h2><p><figure><img src=/paper_images/refrec.png></figure>Adriano Cardace, Riccardo Spezialetti, <strong>Pierluigi Zama Ramirez</strong>, Samuele Salti, and Luigi Di Stefano.<br><em>RefRec: Pseudo-labels Refinement via Shape Reconstruction for Unsupervised 3D Domain Adaptation.</em><br><em><strong>3DV 2021. Oral</strong></em><br><a href=https://github.com/CVLAB-Unibo/RefRec target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/pdf/2110.11036.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/ndr.png></figure>Filippo Aleotti*, Fabio Tosi*, <strong>Pierluigi Zama Ramirez*</strong>, Matteo Poggi, Samuele Salti, Stefano Mattoccia, and Luigi Di Stefano. (*Equal Contribution)<br><em>Neural Disparity Refinement for Arbitrary Resolution Stereo</em><br><em><strong>3DV 2021. Best Paper Honorable Mention</strong></em><br><a href=https://cvlab-unibo.github.io/neural-disparity-refinement-web target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/2110.15367 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/sister.png></figure>Daniele De Gregorio, Matteo Poggi, <strong>Pierluigi Zama Ramirez</strong>, Gianluca Palli, Stefano Mattoccia, and Luigi Di Stefano.<br><em>Beyond the baseline: 3D reconstruction of tiny objects with Single camera Stereo Robot.</em><br><em><strong>IEEE Access</strong></em><br><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=9524696" target=_blank rel="noopener noreffer">[Paper]</a></p><h2 id=2020>2020</h2><p><figure><img src=/paper_images/shootinglabels.png></figure><strong>Pierluigi Zama Ramirez</strong>, Claudio Paternesi, Luca De Luigi, Daniele De Gregorio, and Luigi Di Stefano.<br><em>Shooting Labels: 3D Semantic Labeling by Virtual Reality</em><br><em><strong>AIVR 2020. Best Paper Nominee</strong></em><br><a href=https://cvlab-unibo.github.io/shootinglabelsweb/ target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/1910.05021 target=_blank rel="noopener noreffer">[Paper]</a></p><p><figure><img src=/paper_images/omeganet.png></figure>Fabio Tosi*, Filippo Aleotti*, <strong>Pierluigi Zama Ramirez*</strong>, Matteo Poggi, Samuele Salti, Stefano Mattocia, and Luigi Di Stefano. (*Equal Contribution)<br><em>Distilled Semantics for Comprehensive Scene Understanding from Videos</em><br><em><strong>CVPR 2020</strong></em><br><a href=https://github.com/CVLAB-Unibo/omeganet target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/2003.14030 target=_blank rel="noopener noreffer">[Paper]</a></p><h2 id=2019>2019</h2><p><figure><img src=/paper_images/atdt.png></figure><strong>Pierluigi Zama Ramirez</strong>, Alessio Tonioni, Samuele Salti, and Luigi Di Stefano.<br><em>Learning Across Tasks and Domains</em><br><em><strong>ICCV 2019</strong></em><br><a href=https://github.com/CVLAB-Unibo/ATDT target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/abs/1904.04744 target=_blank rel="noopener noreffer">[Paper]</a></p><p><strong>Pierluigi Zama Ramirez</strong>, Claudio Paternesi, Daniele De Gregorio, and Luigi Di Stefano.<br><em>Shooting Labels by Virtual Reality.</em><br><em><strong>CVPRW 2019</strong></em><br><a href=https://static1.squarespace.com/static/5c3f69e1cc8fedbc039ea739/t/5d01638662182d0001b6f7f6/1560372111582/9_CVPR_2019_VR.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><h2 id=2018>2018</h2><p><strong>Pierluigi Zama Ramirez</strong>, Matteo Poggi, Fabio Tosi, Stefano Mattoccia, and Luigi Di Stefano.<br><em>Geometry meets semantics for semi-supervised monocular depth estimation.</em><br><em><strong>ACCV 2018</strong></em><br><a href=https://github.com/CVLAB-Unibo/Semantic-Mono-Depth target=_blank rel="noopener noreffer">[Project Page]</a>
<a href=https://arxiv.org/pdf/1810.04093.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><p><strong>Pierluigi Zama Ramirez</strong>, Alessio Tonioni, and Luigi Di Stefano.<br><em>Exploiting Semantics in Adversarial Training for Image-Level Domain Adaptation.</em><br><em><strong>International Conference on Image Processing, Applications and Systems (IPAS) 2018</strong></em><br><a href=https://arxiv.org/pdf/1810.05852.pdf target=_blank rel="noopener noreffer">[Paper]</a></p><p><strong>Pierluigi Zama Ramirez</strong>, Alessio Tonioni, and Luigi Di Stefano.<br><em>Domain Adaptation by a Semantic-Aware GAN.</em><br><em><strong>European Machine Vision Association Forum (EMVF) 2018. Oral presentation</strong></em></p><p>Daniele De Gregorio, <strong>Pierluigi Zama Ramirez</strong>, and Luigi Di Stefano.<br><em>Large Scale 3D Semantic Mapping.</em><br><em><strong>European Machine Vision Association Forum (EMVF) 2018. Oral presentation</strong></em></p><p><strong>Pierluigi Zama Ramirez</strong>, Alessio Tonioni, and Luigi Di Stefano.<br><em>A Novel Generative Model to Synthetize Realistic Training Images.</em><br><em><strong>Conference on Imaging Science (SIAM) 2018</strong></em><br><a href=https://www.siam-is18.dm.unibo.it/uploads/store/168f206221f71e84bb90b147edd08fc7.pdf target=_blank rel="noopener noreffer">[Poster]</a></p><h2 id=arxiv>Arxiv</h2><p><strong>Pierluigi Zama Ramirez</strong>, Alessio Tonioni, and Federico Tombari.<br><em>Unsupervised Novel View Synthesis from a Single Image</em><br><a href=https://arxiv.org/pdf/2102.03285.pdf target=_blank rel="noopener noreffer">[Paper]</a></p></div></div></div></main><footer class=footer><div class=footer-container><div class=footer-line itemscope itemtype=http://schema.org/CreativeWork><i class="far fa-copyright fa-fw" aria-hidden=true></i><span itemprop=copyrightYear>2019 - 2024</span>&nbsp;|&nbsp;<span class=license><a rel="license external nofollow noopener noreffer" href=https://creativecommons.org/licenses/by-nc/4.0/ target=_blank>CC BY-NC 4.0</a></span></div></div></footer></div><div id=fixed-buttons><a href=# id=back-to-top class=fixed-button title="Back to Top"><i class="fas fa-arrow-up fa-fw" aria-hidden=true></i>
</a><a href=# id=view-comments class=fixed-button title="View Comments"><i class="fas fa-comment fa-fw" aria-hidden=true></i></a></div><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css><script type=text/javascript src=https://cdn.jsdelivr.net/npm/autocomplete.js@0.38.1/dist/autocomplete.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lunr@2.3.9/lunr.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/lazysizes@5.3.2/lazysizes.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/clipboard@2.0.11/dist/clipboard.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/sharer.js@0.5.1/sharer.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/typeit@8.6.0/dist/index.umd.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/auto-render.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/copy-tex.min.js></script><script type=text/javascript src=https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/contrib/mhchem.min.js></script><script type=text/javascript>window.config={code:{copyTitle:"Copy to clipboard",maxShownLines:50},comment:{},data:{"id-1":"Pierluigi Zama Ramirez","id-2":"Pierluigi Zama Ramirez"},math:{delimiters:[{display:!0,left:"$$",right:"$$"},{display:!0,left:"\\[",right:"\\]"},{display:!0,left:"\\begin{equation}",right:"\\end{equation}"},{display:!0,left:"\\begin{equation*}",right:"\\end{equation*}"},{display:!0,left:"\\begin{align}",right:"\\end{align}"},{display:!0,left:"\\begin{align*}",right:"\\end{align*}"},{display:!0,left:"\\begin{alignat}",right:"\\end{alignat}"},{display:!0,left:"\\begin{alignat*}",right:"\\end{alignat*}"},{display:!0,left:"\\begin{gather}",right:"\\end{gather}"},{display:!0,left:"\\begin{CD}",right:"\\end{CD}"},{display:!1,left:"$",right:"$"},{display:!1,left:"\\(",right:"\\)"}],strict:!1},search:{highlightTag:"em",maxResultLength:10,noResultsFound:"No results found",snippetLength:30},typeit:{cursorChar:"|",cursorSpeed:1e3,data:{"id-1":["id-1"],"id-2":["id-2"]},duration:-1,speed:100}}</script><script type=text/javascript src=/js/theme.min.js></script></body></html>